{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00403d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai, json, pandas as pd, os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98ff5834",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.environ.get('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fbd5a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(prompt, **kwargs):\n",
    "  \"\"\"\n",
    "  wrapper for the API to save the prompt and the result\n",
    "  \"\"\"\n",
    "  props = {\n",
    "  \"engine\":\"davinci\",\n",
    "  \"temperature\":0,\n",
    "  \"max_tokens\":250,\n",
    "  \"stop\":\"\\n\\n\",\n",
    "  **kwargs\n",
    "  }\n",
    "\n",
    "  r = openai.Completion.create(prompt=prompt, **props)[\"choices\"][0][\"text\"].strip()\n",
    "  return r\n",
    "     \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eb52f56b",
   "metadata": {},
   "source": [
    "Making sure this works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ed5ee40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def queryChat(prompt, **kwargs):\n",
    "  \"\"\"\n",
    "  wrapper for the API to easily parse data\n",
    "  \"\"\"\n",
    "  \n",
    "  props = {\n",
    "    \"model\":\"gpt-3.5-turbo\", # using the original davinci\n",
    "    \"n\": 1,\n",
    "    \"temperature\":0, # 0 temperature means it's greedy and gives the same result every time (ish)\n",
    "    \"max_tokens\":250, # 500 tokens should be enough\n",
    "    \"stop\":\"\\n\\n\", # we'll use double newlines to separate the examples\n",
    "    \"messages\": [\n",
    "        {\"role\": \"system\", \"content\": \"You provide the remananing JSON for the user's request. No questions. No comments. Just provide the JSON.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "  }\n",
    "  \n",
    "  props = {**props, **kwargs}\n",
    "  \n",
    "  r = openai.ChatCompletion.create(**props)['choices'][0][\"message\"][\"content\"].strip()\n",
    "  \n",
    "  return r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c6e2112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"question\": \"what is 1+1?\", \"answer\": \"2\"}'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queryChat(\"q: what is 1+1?\\na:\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "86a80dc0",
   "metadata": {},
   "source": [
    "Let's go and start creating some frew shots from the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72f2a90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTargetExample(row):\n",
    "  return f\"\"\"{{\n",
    "    \"Background\": \"{row.context}\",\n",
    "    \"Claim\": \"{row.hypothesis}\",\n",
    "    \"Part of Claim in Background\":\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6060cb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateAnswer(res):\n",
    "    if \"entailment\" in res.lower()[-30:]:\n",
    "        return 'e'\n",
    "    elif \"contradiction\" in res.lower()[-30:]:\n",
    "        return 'c'\n",
    "    return 'n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5664e540",
   "metadata": {},
   "outputs": [],
   "source": [
    "basePrompt = \"\"\"You are an expert analyst evaluating where claims are contradictions, entailments, or neutral with respect to a background. You are given a claim and a background. You must decide whether the claim is a contradiction, entailment, or neutral with respect to the background. You can use the claim and background.\n",
    "{\n",
    "\"Background\": \"The others gave in very soon , and longed to be friends , for now there was no Daisy to pet and cook for them ; no Nan to amuse and doctor them ; and , worst of all , no Mrs. Jo to make home life pleasant and life easy for them .<br>To their great affliction , Mrs. Jo seemed to consider herself one of the offended girls , for she hardly spoke to the outcasts , looked as if she did not see them when she passed , and was always too busy now to attend to their requests .\",\n",
    "\"Claim\": \"Nan was there to doctor them.\",\n",
    "\"Part of Claim in Background\": \"no Nan to amuse and doctor them\",\n",
    "\"Evaluation\": \"In the claim, Nan is there to doctor them. In the background, it is stated that there is no Nan to doctor them. This is inconsistent.\"\n",
    "\"Verdict\": \"Contradiction\"\n",
    "},\n",
    "{\n",
    "\"Background\": \"How to avoid eviction<br>Make timely payments. The easiest way to avoid eviction is to pay your rent on time. Read your lease to see if there is any grace period (such as three or five days).\",\n",
    "\"Claim\": \"most leases have grace periods for payment\",\n",
    "\"Part of Claim in Background\": \"if there is any grace period (such as three or five days)\",\n",
    "\"Evaluation\": \"In the claim, most leases have grace periods for payment. In the background, it is stated that there may be a grace period of three or five days. They neither contradict nor entail each other so it's neutral.\"\n",
    "\"Vedict\": \"Neutral\"\n",
    "},\n",
    "{\n",
    "\"Background\": \"At least 58 people are now dead as a result of the recent flooding in Yemen, and at least 20,000 in the country have no access to shelter. Five people are also reported missing. The Yemeni government has pledged to send tents to help the homeless. The flooding is caused by the recent heavy rain in Yemen, which came as a shock due to the fact that the country only receives several centimeters of rain per year.\",\n",
    "\"Claim\": \"Rising water levels in Yemen has resulted in people passing away\",\n",
    "\"Part of Claim in Background\": \"At least 58 people are now dead as a result of the recent flooding in Yemen\",\n",
    "\"Evaluation\": \"In the claim, rising water levels in Yemen has resulted in people passing away. In the background, it is stated that at least 58 people are now dead as a result of the recent flooding in Yemen. This entails the claim.\",\n",
    "\"Verdict\": \"Entailment\"\n",
    "},\n",
    "{\n",
    "\"Background\": \"I wonder how he expects us to put forward a strong position on these issues if we are not part of the World Trade Organization or if we were not in a position, with meetings like Seattle, where we can pull together different countries from around the world that have a similar position to ours.\",\n",
    "\"Claim\": \"there were never meetings in Seattle\",\n",
    "\"Part of Claim in Background\": \"with meetings like Seattle\",\n",
    "\"Evaluation\": \"In the claim, there were never meetings in Seattle. In the background, it is stated that there were meetings like Seattle. This is inconsistent.\",\n",
    "\"Verdict\": \"Contradiction\"\n",
    "},\n",
    "{\n",
    "\"Background\": \"Luciano Chailly (born Ferrara, January 19, 1920 â€“ died Milan, December 24, 2002) was an Italian composer and arts administrator of French descent. He was the father of harpist Cecilia Chailly, conductor Riccardo Chailly and journalist Floriana Chailly. As a composer, Chailly was best known for his operas, many of which were composed to libretti by Dino Buzzati.\",\n",
    "\"Claim\": \"Luciano Chailly was born in January\",\n",
    "\"Part of Claim in Background\": \"January 19, 1920\",\n",
    "\"Evaluation\": \"In the claim, Luciano Chailly was born in January. In the background, it is stated that he was born on January 19, 1920. This entails the claim.\",\n",
    "\"Verdict\": \"Entailment\"\n",
    "},\n",
    "{\n",
    "\"Background\": \"Oil Vials<br>I purchased several vials of perfumed oils. I picked all sweet scents. They were very realistic, and I was quite pleased. I put some on first thing in the morning. My husband complimented me, as did everyone in the office that day.\",\n",
    "\"Claim\": \"The vials are large.\",\n",
    "\"Part of Claim in Background\": \"None\",\n",
    "\"Evaluation\": \"In the claim, the vials are large. In the background, there is no mention of the size of the vials. This is neutral.\",\n",
    "\"Verdict\": \"Neutral\"\n",
    "},\n",
    "{\n",
    "\"Background\": \"Segura had X-rays on his hand after getting hit by a pitch Friday against the Astros, Shannon Drayer of 710 ESPN Seattle reports. Segura was hit in the eighth inning but did not leave the game. He appears to have avoided a serious injury but is considered day-to-day.\",\n",
    "\"Claim\": \"Segura was hit Friday.,\n",
    "\"Part of Claim in Background\": \"Friday against the Astros\",\n",
    "\"Evaluation\": \"In the claim, Segura was hit Friday. In the background, it is stated that he was hit Friday against the Astros. This entails the claim.\",\n",
    "\"Verdict\": \"Entailment\"\n",
    "},\n",
    "{\n",
    "\"Background\": \"Grudge<br>Tom had a grudge against Ana. He decided he was going to slit her throat. Tom waited in the shadows by Ana's house. When he saw her red coat he lunged out, slicing and stabbing! Tom had only killed Ana's friend, who had borrowed her coat.\",\n",
    "\"Claim\": \"Ana lost her coast\",\n",
    "\"Part of Claim in Background\": \"Ana's friend, who had borrowed her coat\",\n",
    "\"Evaluation\": \"In the claim, Ana lost her coast. In the background, it is stated that Ana's friend had borrowed her coat. This is inconsistent.\",\n",
    "\"Verdict\": \"Contradiction\"\n",
    "},\n",
    "{\n",
    "\"Background\": \"London Calling is the third studio album by English punk rock band the Clash. It was released as a double album in the United Kingdom on 14 December 1979 by Columbia Records, and in the United States in January 1980 by Epic Records. \"London Calling\" is an album that incorporates a range of styles, including punk, reggae, rockabilly, ska, New Orleans R&B, pop, lounge jazz, and hard rock.\",\n",
    "\"Claim\": \"Thanks to the rockabilly and R&B the album was released in the United States in 1980.\",\n",
    "\"Part of Claim in Background\": \"in the United States in January 1980 by Epic Records\",\n",
    "\"Evaluation\": \"In the claim, the album was released in the United States in 1980. In the background, it is stated that it was released in the United States in January 1980 by Epic Records. They neither contradict nor entail each other so it's neutral.\"\n",
    "\"Verdict\": \"Neutral\"\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "72067473",
   "metadata": {},
   "source": [
    "## alright, not great, but let's see if this 9 shot works at all (not feeling great)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad12b087",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = pd.read_json(\"anli_v1.0/R3/dev.jsonl\",lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d69e03e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>context</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>label</th>\n",
       "      <th>model_label</th>\n",
       "      <th>emturk</th>\n",
       "      <th>genre</th>\n",
       "      <th>reason</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50a5d4bc-bb8b-44f9-ba07-95dfaf5536ab</td>\n",
       "      <td>one of the orders issued by Ochola in April Lo...</td>\n",
       "      <td>The decision to move the photocopier business ...</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>False</td>\n",
       "      <td>news</td>\n",
       "      <td>I made an obvious inference from the text that...</td>\n",
       "      <td>r3_dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>08789750-b5fe-478d-8d3f-06a01e3a8b1e</td>\n",
       "      <td>If you can dream it, you can achieve it â€” unle...</td>\n",
       "      <td>The crowd believed they knew the name of the g...</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>False</td>\n",
       "      <td>news</td>\n",
       "      <td>Because the crowd was chanting its name, the c...</td>\n",
       "      <td>r3_dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a960c8cc-2f55-4269-a028-7f714479b068</td>\n",
       "      <td>The Kremlin described as \"complete nonsense\" o...</td>\n",
       "      <td>The Kremlin used the word nonsense multiple ti...</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>False</td>\n",
       "      <td>news</td>\n",
       "      <td>I based my statement on supposed word count ba...</td>\n",
       "      <td>r3_dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>95e97907-0267-45ae-89fc-7e1fce39ee77</td>\n",
       "      <td>Police said that a 21-year-old man was discove...</td>\n",
       "      <td>The victim was less than a quarter century old</td>\n",
       "      <td>e</td>\n",
       "      <td>c</td>\n",
       "      <td>False</td>\n",
       "      <td>news</td>\n",
       "      <td>21 is less than 25. I think the system got it ...</td>\n",
       "      <td>r3_dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5bd3435a-e52e-4688-9bc3-746b47c53469</td>\n",
       "      <td>Hurricane Harvey has caused devastating floods...</td>\n",
       "      <td>Houston is not the only area impacted by Hurri...</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>False</td>\n",
       "      <td>news</td>\n",
       "      <td>Louisiana was also impacted</td>\n",
       "      <td>r3_dev</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    uid  \\\n",
       "0  50a5d4bc-bb8b-44f9-ba07-95dfaf5536ab   \n",
       "1  08789750-b5fe-478d-8d3f-06a01e3a8b1e   \n",
       "2  a960c8cc-2f55-4269-a028-7f714479b068   \n",
       "3  95e97907-0267-45ae-89fc-7e1fce39ee77   \n",
       "4  5bd3435a-e52e-4688-9bc3-746b47c53469   \n",
       "\n",
       "                                             context  \\\n",
       "0  one of the orders issued by Ochola in April Lo...   \n",
       "1  If you can dream it, you can achieve it â€” unle...   \n",
       "2  The Kremlin described as \"complete nonsense\" o...   \n",
       "3  Police said that a 21-year-old man was discove...   \n",
       "4  Hurricane Harvey has caused devastating floods...   \n",
       "\n",
       "                                          hypothesis label model_label  \\\n",
       "0  The decision to move the photocopier business ...     e           n   \n",
       "1  The crowd believed they knew the name of the g...     e           n   \n",
       "2  The Kremlin used the word nonsense multiple ti...     e           n   \n",
       "3     The victim was less than a quarter century old     e           c   \n",
       "4  Houston is not the only area impacted by Hurri...     e           n   \n",
       "\n",
       "   emturk genre                                             reason     tag  \n",
       "0   False  news  I made an obvious inference from the text that...  r3_dev  \n",
       "1   False  news  Because the crowd was chanting its name, the c...  r3_dev  \n",
       "2   False  news  I based my statement on supposed word count ba...  r3_dev  \n",
       "3   False  news  21 is less than 25. I think the system got it ...  r3_dev  \n",
       "4   False  news                        Louisiana was also impacted  r3_dev  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c31fddc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = {}\n",
    "correct = 0\n",
    "done = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0a1929b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 1 of 1200. Score: 1/1 (100.00%)\n",
      "Done 2 of 1200. Score: 2/2 (100.00%)\n",
      "Done 3 of 1200. Score: 3/3 (100.00%)\n",
      "Done 4 of 1200. Score: 4/4 (100.00%)\n",
      "Done 5 of 1200. Score: 5/5 (100.00%)\n",
      "Done 6 of 1200. Score: 6/6 (100.00%)\n",
      "Done 7 of 1200. Score: 6/7 (85.71%)\n",
      "Done 8 of 1200. Score: 6/8 (75.00%)\n",
      "Done 9 of 1200. Score: 6/9 (66.67%)\n",
      "Done 10 of 1200. Score: 7/10 (70.00%)\n",
      "Done 11 of 1200. Score: 7/11 (63.64%)\n",
      "Done 12 of 1200. Score: 8/12 (66.67%)\n",
      "Done 13 of 1200. Score: 9/13 (69.23%)\n",
      "Done 14 of 1200. Score: 10/14 (71.43%)\n",
      "Done 15 of 1200. Score: 10/15 (66.67%)\n",
      "Done 16 of 1200. Score: 11/16 (68.75%)\n",
      "Done 17 of 1200. Score: 11/17 (64.71%)\n",
      "Done 18 of 1200. Score: 11/18 (61.11%)\n",
      "Done 19 of 1200. Score: 11/19 (57.89%)\n",
      "Done 20 of 1200. Score: 11/20 (55.00%)\n",
      "Done 21 of 1200. Score: 12/21 (57.14%)\n",
      "Done 22 of 1200. Score: 13/22 (59.09%)\n",
      "Done 23 of 1200. Score: 14/23 (60.87%)\n",
      "Done 24 of 1200. Score: 14/24 (58.33%)\n",
      "Done 25 of 1200. Score: 14/25 (56.00%)\n",
      "Done 26 of 1200. Score: 14/26 (53.85%)\n",
      "Done 27 of 1200. Score: 15/27 (55.56%)\n",
      "Done 28 of 1200. Score: 16/28 (57.14%)\n",
      "Done 29 of 1200. Score: 16/29 (55.17%)\n",
      "Done 30 of 1200. Score: 16/30 (53.33%)\n",
      "Done 31 of 1200. Score: 16/31 (51.61%)\n",
      "Done 32 of 1200. Score: 17/32 (53.12%)\n",
      "Done 33 of 1200. Score: 17/33 (51.52%)\n",
      "Done 34 of 1200. Score: 17/34 (50.00%)\n",
      "Done 35 of 1200. Score: 18/35 (51.43%)\n",
      "Done 36 of 1200. Score: 19/36 (52.78%)\n",
      "Done 37 of 1200. Score: 19/37 (51.35%)\n",
      "Done 38 of 1200. Score: 20/38 (52.63%)\n",
      "Done 39 of 1200. Score: 20/39 (51.28%)\n",
      "Done 40 of 1200. Score: 20/40 (50.00%)\n",
      "Done 41 of 1200. Score: 21/41 (51.22%)\n",
      "Done 42 of 1200. Score: 21/42 (50.00%)\n",
      "Done 43 of 1200. Score: 22/43 (51.16%)\n",
      "Done 44 of 1200. Score: 23/44 (52.27%)\n",
      "Done 45 of 1200. Score: 24/45 (53.33%)\n",
      "Done 46 of 1200. Score: 25/46 (54.35%)\n",
      "Done 47 of 1200. Score: 26/47 (55.32%)\n",
      "Done 48 of 1200. Score: 27/48 (56.25%)\n",
      "Done 49 of 1200. Score: 28/49 (57.14%)\n",
      "Done 50 of 1200. Score: 28/50 (56.00%)\n",
      "Done 51 of 1200. Score: 29/51 (56.86%)\n",
      "Done 52 of 1200. Score: 30/52 (57.69%)\n",
      "Done 53 of 1200. Score: 31/53 (58.49%)\n",
      "Done 54 of 1200. Score: 32/54 (59.26%)\n",
      "Done 55 of 1200. Score: 33/55 (60.00%)\n",
      "Done 56 of 1200. Score: 33/56 (58.93%)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for row in dev.iterrows():\n",
    "    if row[0] in results_dict:\n",
    "        continue\n",
    "    newPrompt = basePrompt + createTargetExample(row[1])\n",
    "    res = queryChat(newPrompt)\n",
    "    results_dict[row[0]] = {\n",
    "        \"res\": res,\n",
    "        \"label\": row[1].label,\n",
    "        \"pred\": evaluateAnswer(res)\n",
    "    }\n",
    "    done += 1\n",
    "    if evaluateAnswer(res) == row[1].label:\n",
    "        correct += 1\n",
    "    \n",
    "    if done % 10 == 0:\n",
    "        with open(\"turbo-naivefewshot.json\", \"w\") as f:\n",
    "            json.dump(results_dict, f)    \n",
    "    \n",
    "    print(f\"Done {done} of {len(dev)}. Score: {correct}/{done} ({correct/done*100:.2f}%)\")\n",
    "\n",
    "with open(\"turbo-naivefewshot.json\", \"w\") as f:\n",
    "    json.dump(results_dict, f)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e20dece",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
