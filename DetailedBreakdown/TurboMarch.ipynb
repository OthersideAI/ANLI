{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00403d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai, json, pandas as pd, os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98ff5834",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.environ.get('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fbd5a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(prompt, **kwargs):\n",
    "  \"\"\"\n",
    "  wrapper for the API to save the prompt and the result\n",
    "  \"\"\"\n",
    "  props = {\n",
    "  \"engine\":\"text-davinci-003\",\n",
    "  \"temperature\":0,\n",
    "  \"max_tokens\":250,\n",
    "  \"stop\":\"\\n\\n\",\n",
    "  **kwargs\n",
    "  }\n",
    "\n",
    "  r = openai.Completion.create(prompt=prompt, **props)[\"choices\"][0][\"text\"].strip()\n",
    "  return r\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85ca1921",
   "metadata": {},
   "outputs": [],
   "source": [
    "def queryChat(prompt, **kwargs):\n",
    "  \"\"\"\n",
    "  wrapper for the API to easily parse data\n",
    "  \"\"\"\n",
    "  \n",
    "  props = {\n",
    "    \"model\":\"gpt-3.5-turbo-0301\", # using the original davinci\n",
    "    \"n\": 1,\n",
    "    \"temperature\":0, # 0 temperature means it's greedy and gives the same result every time (ish)\n",
    "    \"max_tokens\":250, # 500 tokens should be enough\n",
    "    \"stop\":\"\\n\\n\", # we'll use double newlines to separate the examples\n",
    "    \"messages\": [\n",
    "        {\"role\": \"system\", \"content\": \"You provide the remananing JSON for the user's request. No questions. No comments. Just provide the JSON.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "  }\n",
    "  \n",
    "  props = {**props, **kwargs}\n",
    "  \n",
    "  r = openai.ChatCompletion.create(**props)['choices'][0][\"message\"][\"content\"].strip()\n",
    "  \n",
    "  return r\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eb52f56b",
   "metadata": {},
   "source": [
    "Making sure this works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c6e2112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"query\": \"what is 1+1?\",\\n  \"answer\": \"2\"\\n}'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queryChat(\"q: what is 1+1?\\na:\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "86a80dc0",
   "metadata": {},
   "source": [
    "Let's go and start creating some frew shots from the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f428f63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_json(\"anli_v1.0/R3/train.jsonl\",lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9663e34d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "n    40778\n",
       "e    32292\n",
       "c    27389\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4272abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "basePrompt = \"\"\"You are an expert analyst evaluating where claims are contradictions, entailments, or neutral with respect to a background.\n",
    "\n",
    "{\n",
    "\"StoryA\": \"The others gave in very soon , and longed to be friends , for now there was no Daisy to pet and cook for them ; no Nan to amuse and doctor them ; and , worst of all , no Mrs. Jo to make home life pleasant and life easy for them .<br>To their great affliction , Mrs. Jo seemed to consider herself one of the offended girls , for she hardly spoke to the outcasts , looked as if she did not see them when she passed , and was always too busy now to attend to their requests .\",\n",
    "\"StoryB\": \"Nan was there to doctor them.\",\n",
    "\"Point of Contention\": \"Nan being a doctor\",\n",
    "\"Story A Relevance\": \"No nan to amuse and doctor them\",\n",
    "\"Story B Relevance\": \"Nan was there to doctor them\",\n",
    "\"Explaining the Differences for a Child\": \"In the first story, 'No Nan to amuse and doctor them' means that there was no one to take care of them. In the second story, 'Nan was there to doctor them' means that Nan was there to take care of them. The first sentence says the opposite of the second sentence.\",\n",
    "\"Verdict\": \"Contradiction\"\n",
    "},\n",
    "{\n",
    "\"StoryA\": \"I wonder how he expects us to put forward a strong position on these issues if we are not part of the World Trade Organization or if we were not in a position, with meetings like Seattle, where we can pull together different countries from around the world that have a similar position to ours.\",\n",
    "\"StoryB\": \"there were never meetings in Seattle\",\n",
    "\"Point of Contention\": \"Meetings in Seattle\",\n",
    "\"Story A Relevance\": \"with meetings like Seattle, where we can pull together different countries from around the world that have a similar position to ours.\",\n",
    "\"Story B Relevance\": \"there were never meetings in Seattle\",\n",
    "\"Explaining the Differences for a Child\": \"In the first story, it says that there were meetings in Seattle where different countries could come together. In the second story, it says that there were never meetings in Seattle. The first sentence suggests that there were meetings in Seattle, while the second sentence suggests that there were never any meetings in Seattle.\",\n",
    "\"Verdict\": \"Contradiction\"\n",
    "},\n",
    "{\n",
    "\"StoryA\": \"Luciano Chailly (born Ferrara, January 19, 1920 â€“ died Milan, December 24, 2002) was an Italian composer and arts administrator of French descent. He was the father of harpist Cecilia Chailly, conductor Riccardo Chailly and journalist Floriana Chailly. As a composer, Chailly was best known for his operas, many of which were composed to libretti by Dino Buzzati.\",\n",
    "\"StoryB\": \"Luciano Chailly was born in January\",\n",
    "\"Point of Contention\": \"Luciano Chailly's birth month\",\n",
    "\"Story A Relevance\": \"Luciano Chailly (born Ferrara, January 19, 1920\",\n",
    "\"Story B Relevance\": \"Luciano Chailly was born in January\",\n",
    "\"Explaining the Differences for a Child\": \"In the first story, it says that Luciano Chailly was born in January on the 19th. In the second story, it says that Luciano Chailly was born in January. The first sentence is more specific, saying that Luciano Chailly was born on the 19th of January, while the second sentence is more general, saying that Luciano Chailly was born in January.\",\n",
    "\"Verdict\": \"Entailment\"\n",
    "},\n",
    "{\n",
    "\"StoryA\": \"Segura had X-rays on his hand after getting hit by a pitch Friday against the Astros, Shannon Drayer of 710 ESPN Seattle reports. Segura was hit in the eighth inning but did not leave the game. He appears to have avoided a serious injury but is considered day-to-day.\",\n",
    "\"StoryB\": \"Segura was hit Friday.,\n",
    "\"Point of Contention\": \"Segura being hit by a pitch\",\n",
    "\"Story A Relevance\": \"Segura had X-rays on his hand after getting hit by a pitch Friday against the Astros\",\n",
    "\"Story B Relevance\": \"Segura was hit Friday.\",\n",
    "\"Explaining the Differences for a Child\": \"In the first story, it says that Segura had X-rays on his hand after getting hit by a pitch on Friday. In the second story, it says that Segura was hit on Friday. The first sentence is more specific, saying that Segura was hit by a pitch, while the second sentence is more general, saying that Segura was hit on Friday.\",\n",
    "\"Verdict\": \"Entailment\"\n",
    "},\n",
    "{\n",
    "\"StoryA\": \"Grudge<br>Tom had a grudge against Ana. He decided he was going to slit her throat. Tom waited in the shadows by Ana's house. When he saw her red coat he lunged out, slicing and stabbing! Tom had only killed Ana's friend, who had borrowed her coat.\",\n",
    "\"StoryB\": \"Ana lost her coast\",\n",
    "\"Point of Contention\": \"Ana losing her coat\",\n",
    "\"Story A Relevance\": \"When he saw her red coat he lunged out, slicing and stabbing!\",\n",
    "\"Story B Relevance\": \"Ana lost her coast\",\n",
    "\"Explaining the Differences for a Child\": \"In the first story, it says that Tom lunged out when he saw Ana's red coat. In the second story, it says that Ana lost her coat. The first sentence suggests that Ana still had her coat, while the second sentence suggests that Ana no longer had her coat.\",\n",
    "\"Verdict\": \"Contradiction\"\n",
    "},\n",
    "{\n",
    "\"StoryA\": \"London Calling is the third studio album by English punk rock band the Clash. It was released as a double album in the United Kingdom on 14 December 1979 by Columbia Records, and in the United States in January 1980 by Epic Records. \"London Calling\" is an album that incorporates a range of styles, including punk, reggae, rockabilly, ska, New Orleans R&B, pop, lounge jazz, and hard rock.\",\n",
    "\"StoryB\": \"Thanks to the rockabilly and R&B the album was released in the United States in 1980.\",\n",
    "\"Point of Contention\": \"Album being released in the United States in 1980\",\n",
    "\"Story A Relevance\": \"London Calling was released in the United States in January 1980 by Epic Records.\",\n",
    "\"Story B Relevance\": \"Thanks to the rockabilly and R&B the album was released in the United States in 1980.\",\n",
    "\"Explaining the Differences for a Child\": \"In the first story, it says that the album was released in the United States in January 1980. In the second story, it says that the album was released in the United States in 1980 thanks to the rockabilly and R&B the album. They both agree that it was released in 1980 but there is nothing in the first story that relates to whether it was released thanks to the rockabilly and R&B the album.\",\n",
    "\"Verdict\": \"Neutral\"\n",
    "}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e1bef24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTargetExample(row):\n",
    "  return f\"\"\"{{\n",
    "    \"StoryA\": \"{row.context}\",\n",
    "    \"StoryB\": \"{row.hypothesis}\",\n",
    "    \"Point of Contention\":\"\"\"\n",
    "    \n",
    "def evaluateAnswer(res):\n",
    "    if \"entailment\" in res.lower()[-30:]:\n",
    "        return 'e'\n",
    "    elif \"contradiction\" in res.lower()[-30:]:\n",
    "        return 'c'\n",
    "    return 'n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad12b087",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = pd.read_json(\"anli_v1.0/R3/dev.jsonl\",lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d69e03e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>context</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>label</th>\n",
       "      <th>model_label</th>\n",
       "      <th>emturk</th>\n",
       "      <th>genre</th>\n",
       "      <th>reason</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50a5d4bc-bb8b-44f9-ba07-95dfaf5536ab</td>\n",
       "      <td>one of the orders issued by Ochola in April Lo...</td>\n",
       "      <td>The decision to move the photocopier business ...</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>False</td>\n",
       "      <td>news</td>\n",
       "      <td>I made an obvious inference from the text that...</td>\n",
       "      <td>r3_dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>08789750-b5fe-478d-8d3f-06a01e3a8b1e</td>\n",
       "      <td>If you can dream it, you can achieve it â€” unle...</td>\n",
       "      <td>The crowd believed they knew the name of the g...</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>False</td>\n",
       "      <td>news</td>\n",
       "      <td>Because the crowd was chanting its name, the c...</td>\n",
       "      <td>r3_dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a960c8cc-2f55-4269-a028-7f714479b068</td>\n",
       "      <td>The Kremlin described as \"complete nonsense\" o...</td>\n",
       "      <td>The Kremlin used the word nonsense multiple ti...</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>False</td>\n",
       "      <td>news</td>\n",
       "      <td>I based my statement on supposed word count ba...</td>\n",
       "      <td>r3_dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>95e97907-0267-45ae-89fc-7e1fce39ee77</td>\n",
       "      <td>Police said that a 21-year-old man was discove...</td>\n",
       "      <td>The victim was less than a quarter century old</td>\n",
       "      <td>e</td>\n",
       "      <td>c</td>\n",
       "      <td>False</td>\n",
       "      <td>news</td>\n",
       "      <td>21 is less than 25. I think the system got it ...</td>\n",
       "      <td>r3_dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5bd3435a-e52e-4688-9bc3-746b47c53469</td>\n",
       "      <td>Hurricane Harvey has caused devastating floods...</td>\n",
       "      <td>Houston is not the only area impacted by Hurri...</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>False</td>\n",
       "      <td>news</td>\n",
       "      <td>Louisiana was also impacted</td>\n",
       "      <td>r3_dev</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    uid  \\\n",
       "0  50a5d4bc-bb8b-44f9-ba07-95dfaf5536ab   \n",
       "1  08789750-b5fe-478d-8d3f-06a01e3a8b1e   \n",
       "2  a960c8cc-2f55-4269-a028-7f714479b068   \n",
       "3  95e97907-0267-45ae-89fc-7e1fce39ee77   \n",
       "4  5bd3435a-e52e-4688-9bc3-746b47c53469   \n",
       "\n",
       "                                             context  \\\n",
       "0  one of the orders issued by Ochola in April Lo...   \n",
       "1  If you can dream it, you can achieve it â€” unle...   \n",
       "2  The Kremlin described as \"complete nonsense\" o...   \n",
       "3  Police said that a 21-year-old man was discove...   \n",
       "4  Hurricane Harvey has caused devastating floods...   \n",
       "\n",
       "                                          hypothesis label model_label  \\\n",
       "0  The decision to move the photocopier business ...     e           n   \n",
       "1  The crowd believed they knew the name of the g...     e           n   \n",
       "2  The Kremlin used the word nonsense multiple ti...     e           n   \n",
       "3     The victim was less than a quarter century old     e           c   \n",
       "4  Houston is not the only area impacted by Hurri...     e           n   \n",
       "\n",
       "   emturk genre                                             reason     tag  \n",
       "0   False  news  I made an obvious inference from the text that...  r3_dev  \n",
       "1   False  news  Because the crowd was chanting its name, the c...  r3_dev  \n",
       "2   False  news  I based my statement on supposed word count ba...  r3_dev  \n",
       "3   False  news  21 is less than 25. I think the system got it ...  r3_dev  \n",
       "4   False  news                        Louisiana was also impacted  r3_dev  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c31fddc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = {}\n",
    "correct = 0\n",
    "done = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0a1929b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 939 of 1200. Score: 471/939 (50.16%)\n",
      "Done 940 of 1200. Score: 472/940 (50.21%)\n",
      "Done 941 of 1200. Score: 472/941 (50.16%)\n",
      "Done 942 of 1200. Score: 472/942 (50.11%)\n",
      "Done 943 of 1200. Score: 472/943 (50.05%)\n",
      "Done 944 of 1200. Score: 473/944 (50.11%)\n",
      "Done 945 of 1200. Score: 473/945 (50.05%)\n",
      "Done 946 of 1200. Score: 473/946 (50.00%)\n",
      "Done 947 of 1200. Score: 474/947 (50.05%)\n",
      "Done 948 of 1200. Score: 474/948 (50.00%)\n",
      "Done 949 of 1200. Score: 474/949 (49.95%)\n",
      "Done 950 of 1200. Score: 474/950 (49.89%)\n",
      "Done 951 of 1200. Score: 474/951 (49.84%)\n",
      "Done 952 of 1200. Score: 474/952 (49.79%)\n",
      "Done 953 of 1200. Score: 475/953 (49.84%)\n",
      "Done 954 of 1200. Score: 476/954 (49.90%)\n",
      "Done 955 of 1200. Score: 476/955 (49.84%)\n",
      "Done 956 of 1200. Score: 477/956 (49.90%)\n",
      "Done 957 of 1200. Score: 477/957 (49.84%)\n",
      "Done 958 of 1200. Score: 477/958 (49.79%)\n",
      "Done 959 of 1200. Score: 477/959 (49.74%)\n",
      "Done 960 of 1200. Score: 478/960 (49.79%)\n",
      "Done 961 of 1200. Score: 479/961 (49.84%)\n",
      "Done 962 of 1200. Score: 480/962 (49.90%)\n",
      "Done 963 of 1200. Score: 481/963 (49.95%)\n",
      "Done 964 of 1200. Score: 482/964 (50.00%)\n",
      "Done 965 of 1200. Score: 482/965 (49.95%)\n",
      "Done 966 of 1200. Score: 483/966 (50.00%)\n",
      "Done 967 of 1200. Score: 483/967 (49.95%)\n",
      "Done 968 of 1200. Score: 483/968 (49.90%)\n",
      "Done 969 of 1200. Score: 483/969 (49.85%)\n",
      "Done 970 of 1200. Score: 483/970 (49.79%)\n",
      "Done 971 of 1200. Score: 484/971 (49.85%)\n",
      "Done 972 of 1200. Score: 485/972 (49.90%)\n",
      "Done 973 of 1200. Score: 486/973 (49.95%)\n",
      "Done 974 of 1200. Score: 487/974 (50.00%)\n",
      "Done 975 of 1200. Score: 487/975 (49.95%)\n",
      "Done 976 of 1200. Score: 488/976 (50.00%)\n",
      "Done 977 of 1200. Score: 489/977 (50.05%)\n",
      "Done 978 of 1200. Score: 490/978 (50.10%)\n",
      "Done 979 of 1200. Score: 490/979 (50.05%)\n",
      "Done 980 of 1200. Score: 491/980 (50.10%)\n",
      "Done 981 of 1200. Score: 491/981 (50.05%)\n",
      "Done 982 of 1200. Score: 491/982 (50.00%)\n",
      "Done 983 of 1200. Score: 492/983 (50.05%)\n",
      "Done 984 of 1200. Score: 492/984 (50.00%)\n",
      "Done 985 of 1200. Score: 492/985 (49.95%)\n",
      "Done 986 of 1200. Score: 492/986 (49.90%)\n",
      "Done 987 of 1200. Score: 492/987 (49.85%)\n",
      "Done 988 of 1200. Score: 493/988 (49.90%)\n",
      "Done 989 of 1200. Score: 494/989 (49.95%)\n",
      "Done 990 of 1200. Score: 494/990 (49.90%)\n",
      "Done 991 of 1200. Score: 494/991 (49.85%)\n",
      "Done 992 of 1200. Score: 495/992 (49.90%)\n",
      "Done 993 of 1200. Score: 495/993 (49.85%)\n",
      "Done 994 of 1200. Score: 495/994 (49.80%)\n",
      "Done 995 of 1200. Score: 496/995 (49.85%)\n",
      "Done 996 of 1200. Score: 497/996 (49.90%)\n",
      "Done 997 of 1200. Score: 498/997 (49.95%)\n",
      "Done 998 of 1200. Score: 499/998 (50.00%)\n",
      "Done 999 of 1200. Score: 500/999 (50.05%)\n",
      "Done 1000 of 1200. Score: 501/1000 (50.10%)\n",
      "Done 1001 of 1200. Score: 501/1001 (50.05%)\n",
      "Done 1002 of 1200. Score: 502/1002 (50.10%)\n",
      "Done 1003 of 1200. Score: 503/1003 (50.15%)\n",
      "Done 1004 of 1200. Score: 503/1004 (50.10%)\n",
      "Done 1005 of 1200. Score: 503/1005 (50.05%)\n",
      "Done 1006 of 1200. Score: 503/1006 (50.00%)\n",
      "Done 1007 of 1200. Score: 503/1007 (49.95%)\n",
      "Done 1008 of 1200. Score: 504/1008 (50.00%)\n",
      "Done 1009 of 1200. Score: 504/1009 (49.95%)\n",
      "Done 1010 of 1200. Score: 505/1010 (50.00%)\n",
      "Done 1011 of 1200. Score: 505/1011 (49.95%)\n",
      "Done 1012 of 1200. Score: 506/1012 (50.00%)\n",
      "Done 1013 of 1200. Score: 507/1013 (50.05%)\n",
      "Done 1014 of 1200. Score: 507/1014 (50.00%)\n",
      "Done 1015 of 1200. Score: 508/1015 (50.05%)\n",
      "Done 1016 of 1200. Score: 508/1016 (50.00%)\n",
      "Done 1017 of 1200. Score: 508/1017 (49.95%)\n",
      "Done 1018 of 1200. Score: 508/1018 (49.90%)\n",
      "Done 1019 of 1200. Score: 508/1019 (49.85%)\n",
      "Done 1020 of 1200. Score: 508/1020 (49.80%)\n",
      "Done 1021 of 1200. Score: 509/1021 (49.85%)\n",
      "Done 1022 of 1200. Score: 509/1022 (49.80%)\n",
      "Done 1023 of 1200. Score: 510/1023 (49.85%)\n",
      "Done 1024 of 1200. Score: 511/1024 (49.90%)\n",
      "Done 1025 of 1200. Score: 512/1025 (49.95%)\n",
      "Done 1026 of 1200. Score: 513/1026 (50.00%)\n",
      "Done 1027 of 1200. Score: 513/1027 (49.95%)\n",
      "Done 1028 of 1200. Score: 514/1028 (50.00%)\n",
      "Done 1029 of 1200. Score: 514/1029 (49.95%)\n",
      "Done 1030 of 1200. Score: 514/1030 (49.90%)\n",
      "Done 1031 of 1200. Score: 514/1031 (49.85%)\n",
      "Done 1032 of 1200. Score: 514/1032 (49.81%)\n",
      "Done 1033 of 1200. Score: 514/1033 (49.76%)\n",
      "Done 1034 of 1200. Score: 514/1034 (49.71%)\n",
      "Done 1035 of 1200. Score: 515/1035 (49.76%)\n",
      "Done 1036 of 1200. Score: 515/1036 (49.71%)\n",
      "Done 1037 of 1200. Score: 516/1037 (49.76%)\n",
      "Done 1038 of 1200. Score: 516/1038 (49.71%)\n",
      "Done 1039 of 1200. Score: 516/1039 (49.66%)\n",
      "Done 1040 of 1200. Score: 517/1040 (49.71%)\n",
      "Done 1041 of 1200. Score: 518/1041 (49.76%)\n",
      "Done 1042 of 1200. Score: 519/1042 (49.81%)\n",
      "Done 1043 of 1200. Score: 520/1043 (49.86%)\n",
      "Done 1044 of 1200. Score: 521/1044 (49.90%)\n",
      "Done 1045 of 1200. Score: 521/1045 (49.86%)\n",
      "Done 1046 of 1200. Score: 521/1046 (49.81%)\n",
      "Done 1047 of 1200. Score: 521/1047 (49.76%)\n",
      "Done 1048 of 1200. Score: 522/1048 (49.81%)\n",
      "Done 1049 of 1200. Score: 522/1049 (49.76%)\n",
      "Done 1050 of 1200. Score: 523/1050 (49.81%)\n",
      "Done 1051 of 1200. Score: 524/1051 (49.86%)\n",
      "Done 1052 of 1200. Score: 525/1052 (49.90%)\n",
      "Done 1053 of 1200. Score: 525/1053 (49.86%)\n",
      "Done 1054 of 1200. Score: 525/1054 (49.81%)\n",
      "Done 1055 of 1200. Score: 526/1055 (49.86%)\n",
      "Done 1056 of 1200. Score: 526/1056 (49.81%)\n",
      "Done 1057 of 1200. Score: 526/1057 (49.76%)\n",
      "Done 1058 of 1200. Score: 527/1058 (49.81%)\n",
      "Done 1059 of 1200. Score: 528/1059 (49.86%)\n",
      "Done 1060 of 1200. Score: 529/1060 (49.91%)\n",
      "Done 1061 of 1200. Score: 530/1061 (49.95%)\n",
      "Done 1062 of 1200. Score: 530/1062 (49.91%)\n",
      "Done 1063 of 1200. Score: 531/1063 (49.95%)\n",
      "Done 1064 of 1200. Score: 531/1064 (49.91%)\n",
      "Done 1065 of 1200. Score: 532/1065 (49.95%)\n",
      "Done 1066 of 1200. Score: 533/1066 (50.00%)\n",
      "Done 1067 of 1200. Score: 534/1067 (50.05%)\n",
      "Done 1068 of 1200. Score: 534/1068 (50.00%)\n",
      "Done 1069 of 1200. Score: 534/1069 (49.95%)\n",
      "Done 1070 of 1200. Score: 534/1070 (49.91%)\n",
      "Done 1071 of 1200. Score: 535/1071 (49.95%)\n",
      "Done 1072 of 1200. Score: 535/1072 (49.91%)\n",
      "Done 1073 of 1200. Score: 536/1073 (49.95%)\n",
      "Done 1074 of 1200. Score: 537/1074 (50.00%)\n",
      "Done 1075 of 1200. Score: 538/1075 (50.05%)\n",
      "Done 1076 of 1200. Score: 539/1076 (50.09%)\n",
      "Done 1077 of 1200. Score: 540/1077 (50.14%)\n",
      "Done 1078 of 1200. Score: 540/1078 (50.09%)\n",
      "Done 1079 of 1200. Score: 540/1079 (50.05%)\n",
      "Done 1080 of 1200. Score: 541/1080 (50.09%)\n",
      "Done 1081 of 1200. Score: 542/1081 (50.14%)\n",
      "Done 1082 of 1200. Score: 543/1082 (50.18%)\n",
      "Done 1083 of 1200. Score: 544/1083 (50.23%)\n",
      "Done 1084 of 1200. Score: 545/1084 (50.28%)\n",
      "Done 1085 of 1200. Score: 546/1085 (50.32%)\n",
      "Done 1086 of 1200. Score: 547/1086 (50.37%)\n",
      "Done 1087 of 1200. Score: 548/1087 (50.41%)\n",
      "Done 1088 of 1200. Score: 548/1088 (50.37%)\n",
      "Done 1089 of 1200. Score: 549/1089 (50.41%)\n",
      "Done 1090 of 1200. Score: 550/1090 (50.46%)\n",
      "Done 1091 of 1200. Score: 550/1091 (50.41%)\n",
      "Done 1092 of 1200. Score: 551/1092 (50.46%)\n",
      "Done 1093 of 1200. Score: 551/1093 (50.41%)\n",
      "Done 1094 of 1200. Score: 551/1094 (50.37%)\n",
      "Done 1095 of 1200. Score: 552/1095 (50.41%)\n",
      "Done 1096 of 1200. Score: 552/1096 (50.36%)\n",
      "Done 1097 of 1200. Score: 552/1097 (50.32%)\n",
      "Done 1098 of 1200. Score: 552/1098 (50.27%)\n",
      "Done 1099 of 1200. Score: 552/1099 (50.23%)\n",
      "Done 1100 of 1200. Score: 553/1100 (50.27%)\n",
      "Done 1101 of 1200. Score: 554/1101 (50.32%)\n",
      "Done 1102 of 1200. Score: 555/1102 (50.36%)\n",
      "Done 1103 of 1200. Score: 556/1103 (50.41%)\n",
      "Done 1104 of 1200. Score: 556/1104 (50.36%)\n",
      "Done 1105 of 1200. Score: 557/1105 (50.41%)\n",
      "Done 1106 of 1200. Score: 557/1106 (50.36%)\n",
      "Done 1107 of 1200. Score: 558/1107 (50.41%)\n",
      "Done 1108 of 1200. Score: 559/1108 (50.45%)\n",
      "Done 1109 of 1200. Score: 560/1109 (50.50%)\n",
      "Done 1110 of 1200. Score: 560/1110 (50.45%)\n",
      "Done 1111 of 1200. Score: 560/1111 (50.41%)\n",
      "Done 1112 of 1200. Score: 561/1112 (50.45%)\n",
      "Done 1113 of 1200. Score: 561/1113 (50.40%)\n",
      "Done 1114 of 1200. Score: 561/1114 (50.36%)\n",
      "Done 1115 of 1200. Score: 561/1115 (50.31%)\n",
      "Done 1116 of 1200. Score: 562/1116 (50.36%)\n",
      "Done 1117 of 1200. Score: 563/1117 (50.40%)\n",
      "Done 1118 of 1200. Score: 563/1118 (50.36%)\n",
      "Done 1119 of 1200. Score: 564/1119 (50.40%)\n",
      "Done 1120 of 1200. Score: 565/1120 (50.45%)\n",
      "Done 1121 of 1200. Score: 566/1121 (50.49%)\n",
      "Done 1122 of 1200. Score: 567/1122 (50.53%)\n",
      "Done 1123 of 1200. Score: 568/1123 (50.58%)\n",
      "Done 1124 of 1200. Score: 569/1124 (50.62%)\n",
      "Done 1125 of 1200. Score: 569/1125 (50.58%)\n",
      "Done 1126 of 1200. Score: 569/1126 (50.53%)\n",
      "Done 1127 of 1200. Score: 569/1127 (50.49%)\n",
      "Done 1128 of 1200. Score: 570/1128 (50.53%)\n",
      "Done 1129 of 1200. Score: 570/1129 (50.49%)\n",
      "Done 1130 of 1200. Score: 570/1130 (50.44%)\n",
      "Done 1131 of 1200. Score: 570/1131 (50.40%)\n",
      "Done 1132 of 1200. Score: 571/1132 (50.44%)\n",
      "Done 1133 of 1200. Score: 571/1133 (50.40%)\n",
      "Done 1134 of 1200. Score: 572/1134 (50.44%)\n",
      "Done 1135 of 1200. Score: 572/1135 (50.40%)\n",
      "Done 1136 of 1200. Score: 572/1136 (50.35%)\n",
      "Done 1137 of 1200. Score: 573/1137 (50.40%)\n",
      "Done 1138 of 1200. Score: 574/1138 (50.44%)\n",
      "Done 1139 of 1200. Score: 575/1139 (50.48%)\n",
      "Done 1140 of 1200. Score: 575/1140 (50.44%)\n",
      "Done 1141 of 1200. Score: 575/1141 (50.39%)\n",
      "Done 1142 of 1200. Score: 575/1142 (50.35%)\n",
      "Done 1143 of 1200. Score: 576/1143 (50.39%)\n",
      "Done 1144 of 1200. Score: 577/1144 (50.44%)\n",
      "Done 1145 of 1200. Score: 577/1145 (50.39%)\n",
      "Done 1146 of 1200. Score: 577/1146 (50.35%)\n",
      "Done 1147 of 1200. Score: 577/1147 (50.31%)\n",
      "Done 1148 of 1200. Score: 578/1148 (50.35%)\n",
      "Done 1149 of 1200. Score: 579/1149 (50.39%)\n",
      "Done 1150 of 1200. Score: 579/1150 (50.35%)\n",
      "Done 1151 of 1200. Score: 580/1151 (50.39%)\n",
      "Done 1152 of 1200. Score: 581/1152 (50.43%)\n",
      "Done 1153 of 1200. Score: 582/1153 (50.48%)\n",
      "Done 1154 of 1200. Score: 583/1154 (50.52%)\n",
      "Done 1155 of 1200. Score: 584/1155 (50.56%)\n",
      "Done 1156 of 1200. Score: 584/1156 (50.52%)\n",
      "Done 1157 of 1200. Score: 585/1157 (50.56%)\n",
      "Done 1158 of 1200. Score: 586/1158 (50.60%)\n",
      "Done 1159 of 1200. Score: 586/1159 (50.56%)\n",
      "Done 1160 of 1200. Score: 586/1160 (50.52%)\n",
      "Done 1161 of 1200. Score: 587/1161 (50.56%)\n",
      "Done 1162 of 1200. Score: 588/1162 (50.60%)\n",
      "Done 1163 of 1200. Score: 588/1163 (50.56%)\n",
      "Done 1164 of 1200. Score: 589/1164 (50.60%)\n",
      "Done 1165 of 1200. Score: 589/1165 (50.56%)\n",
      "Done 1166 of 1200. Score: 589/1166 (50.51%)\n",
      "Done 1167 of 1200. Score: 590/1167 (50.56%)\n",
      "Done 1168 of 1200. Score: 591/1168 (50.60%)\n",
      "Done 1169 of 1200. Score: 591/1169 (50.56%)\n",
      "Done 1170 of 1200. Score: 592/1170 (50.60%)\n",
      "Done 1171 of 1200. Score: 592/1171 (50.56%)\n",
      "Done 1172 of 1200. Score: 593/1172 (50.60%)\n",
      "Done 1173 of 1200. Score: 594/1173 (50.64%)\n",
      "Done 1174 of 1200. Score: 595/1174 (50.68%)\n",
      "Done 1175 of 1200. Score: 595/1175 (50.64%)\n",
      "Done 1176 of 1200. Score: 595/1176 (50.60%)\n",
      "Done 1177 of 1200. Score: 596/1177 (50.64%)\n",
      "Done 1178 of 1200. Score: 597/1178 (50.68%)\n",
      "Done 1179 of 1200. Score: 598/1179 (50.72%)\n",
      "Done 1180 of 1200. Score: 598/1180 (50.68%)\n",
      "Done 1181 of 1200. Score: 598/1181 (50.64%)\n",
      "Done 1182 of 1200. Score: 598/1182 (50.59%)\n",
      "Done 1183 of 1200. Score: 599/1183 (50.63%)\n",
      "Done 1184 of 1200. Score: 600/1184 (50.68%)\n",
      "Done 1185 of 1200. Score: 601/1185 (50.72%)\n",
      "Done 1186 of 1200. Score: 601/1186 (50.67%)\n",
      "Done 1187 of 1200. Score: 602/1187 (50.72%)\n",
      "Done 1188 of 1200. Score: 603/1188 (50.76%)\n",
      "Done 1189 of 1200. Score: 604/1189 (50.80%)\n",
      "Done 1190 of 1200. Score: 604/1190 (50.76%)\n",
      "Done 1191 of 1200. Score: 605/1191 (50.80%)\n",
      "Done 1192 of 1200. Score: 605/1192 (50.76%)\n",
      "Done 1193 of 1200. Score: 606/1193 (50.80%)\n",
      "Done 1194 of 1200. Score: 607/1194 (50.84%)\n",
      "Done 1195 of 1200. Score: 607/1195 (50.79%)\n",
      "Done 1196 of 1200. Score: 608/1196 (50.84%)\n",
      "Done 1197 of 1200. Score: 608/1197 (50.79%)\n",
      "Done 1198 of 1200. Score: 609/1198 (50.83%)\n",
      "Done 1199 of 1200. Score: 610/1199 (50.88%)\n",
      "Done 1200 of 1200. Score: 611/1200 (50.92%)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for row in dev.iterrows():\n",
    "    if row[0] in results_dict:\n",
    "        continue\n",
    "    newPrompt = basePrompt + createTargetExample(row[1])\n",
    "    res = queryChat(newPrompt, stop=\"}\")\n",
    "    results_dict[row[0]] = {\n",
    "        \"res\": res,\n",
    "        \"label\": row[1].label,\n",
    "        \"pred\": evaluateAnswer(res)\n",
    "    }\n",
    "    done += 1\n",
    "    if evaluateAnswer(res) == row[1].label:\n",
    "        correct += 1\n",
    "    print(f\"Done {done} of {len(dev)}. Score: {correct}/{done} ({correct/done*100:.2f}%)\")\n",
    "    if done % 10 == 0:\n",
    "        with open(\"turbomarch-inDepthFewShot.json\", \"w\") as f:\n",
    "            json.dump(results_dict, f)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e20dece",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"turbomarch-inDepthFewShot.json\", \"w\") as f:\n",
    "    json.dump(results_dict, f)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf2ed63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
