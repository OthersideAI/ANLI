{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00403d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai, json, pandas as pd, os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98ff5834",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.environ.get('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fbd5a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(prompt, **kwargs):\n",
    "  \"\"\"\n",
    "  wrapper for the API to save the prompt and the result\n",
    "  \"\"\"\n",
    "  props = {\n",
    "  \"engine\":\"davinci\",\n",
    "  \"temperature\":0,\n",
    "  \"max_tokens\":250,\n",
    "  \"stop\":\"\\n\\n\",\n",
    "  **kwargs\n",
    "  }\n",
    "\n",
    "  r = openai.Completion.create(prompt=prompt, **props)[\"choices\"][0][\"text\"].strip()\n",
    "  return r\n",
    "     \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eb52f56b",
   "metadata": {},
   "source": [
    "Making sure this works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c6e2112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query(\"q: what is 1+1?\\na:\", stop=\"\\n\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "86a80dc0",
   "metadata": {},
   "source": [
    "Let's go and start creating some frew shots from the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f428f63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_json(\"anli_v1.0/R3/train.jsonl\",lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9663e34d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "n    40778\n",
       "e    32292\n",
       "c    27389\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b4272abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "basePrompt = \"\"\"You are an expert analyst evaluating where claims are contradictions, entailments, or neutral with respect to a background.\n",
    "\n",
    "{\n",
    "\"StoryA\": \"The others gave in very soon , and longed to be friends , for now there was no Daisy to pet and cook for them ; no Nan to amuse and doctor them ; and , worst of all , no Mrs. Jo to make home life pleasant and life easy for them .<br>To their great affliction , Mrs. Jo seemed to consider herself one of the offended girls , for she hardly spoke to the outcasts , looked as if she did not see them when she passed , and was always too busy now to attend to their requests .\",\n",
    "\"StoryB\": \"Nan was there to doctor them.\",\n",
    "\"Point of Contention\": \"Nan being a doctor\",\n",
    "\"Story A Relevance\": \"No nan to amuse and doctor them\",\n",
    "\"Story B Relevance\": \"Nan was there to doctor them\",\n",
    "\"Explaining the Differences for a Child\": \"In the first story, 'No Nan to amuse and doctor them' means that there was no one to take care of them. In the second story, 'Nan was there to doctor them' means that Nan was there to take care of them. The first sentence says the opposite of the second sentence.\",\n",
    "\"Verdict\": \"Contradiction\"\n",
    "},\n",
    "{\n",
    "\"StoryA\": \"I wonder how he expects us to put forward a strong position on these issues if we are not part of the World Trade Organization or if we were not in a position, with meetings like Seattle, where we can pull together different countries from around the world that have a similar position to ours.\",\n",
    "\"StoryB\": \"there were never meetings in Seattle\",\n",
    "\"Point of Contention\": \"Meetings in Seattle\",\n",
    "\"Story A Relevance\": \"with meetings like Seattle, where we can pull together different countries from around the world that have a similar position to ours.\",\n",
    "\"Story B Relevance\": \"there were never meetings in Seattle\",\n",
    "\"Explaining the Differences for a Child\": \"In the first story, it says that there were meetings in Seattle where different countries could come together. In the second story, it says that there were never meetings in Seattle. The first sentence suggests that there were meetings in Seattle, while the second sentence suggests that there were never any meetings in Seattle.\",\n",
    "\"Verdict\": \"Contradiction\"\n",
    "},\n",
    "{\n",
    "\"StoryA\": \"Luciano Chailly (born Ferrara, January 19, 1920 â€“ died Milan, December 24, 2002) was an Italian composer and arts administrator of French descent. He was the father of harpist Cecilia Chailly, conductor Riccardo Chailly and journalist Floriana Chailly. As a composer, Chailly was best known for his operas, many of which were composed to libretti by Dino Buzzati.\",\n",
    "\"StoryB\": \"Luciano Chailly was born in January\",\n",
    "\"Point of Contention\": \"Luciano Chailly's birth month\",\n",
    "\"Story A Relevance\": \"Luciano Chailly (born Ferrara, January 19, 1920\",\n",
    "\"Story B Relevance\": \"Luciano Chailly was born in January\",\n",
    "\"Explaining the Differences for a Child\": \"In the first story, it says that Luciano Chailly was born in January on the 19th. In the second story, it says that Luciano Chailly was born in January. The first sentence is more specific, saying that Luciano Chailly was born on the 19th of January, while the second sentence is more general, saying that Luciano Chailly was born in January.\",\n",
    "\"Verdict\": \"Entailment\"\n",
    "},\n",
    "{\n",
    "\"StoryA\": \"Segura had X-rays on his hand after getting hit by a pitch Friday against the Astros, Shannon Drayer of 710 ESPN Seattle reports. Segura was hit in the eighth inning but did not leave the game. He appears to have avoided a serious injury but is considered day-to-day.\",\n",
    "\"StoryB\": \"Segura was hit Friday.,\n",
    "\"Point of Contention\": \"Segura being hit by a pitch\",\n",
    "\"Story A Relevance\": \"Segura had X-rays on his hand after getting hit by a pitch Friday against the Astros\",\n",
    "\"Story B Relevance\": \"Segura was hit Friday.\",\n",
    "\"Explaining the Differences for a Child\": \"In the first story, it says that Segura had X-rays on his hand after getting hit by a pitch on Friday. In the second story, it says that Segura was hit on Friday. The first sentence is more specific, saying that Segura was hit by a pitch, while the second sentence is more general, saying that Segura was hit on Friday.\",\n",
    "\"Verdict\": \"Entailment\"\n",
    "},\n",
    "{\n",
    "\"StoryA\": \"Grudge<br>Tom had a grudge against Ana. He decided he was going to slit her throat. Tom waited in the shadows by Ana's house. When he saw her red coat he lunged out, slicing and stabbing! Tom had only killed Ana's friend, who had borrowed her coat.\",\n",
    "\"StoryB\": \"Ana lost her coast\",\n",
    "\"Point of Contention\": \"Ana losing her coat\",\n",
    "\"Story A Relevance\": \"When he saw her red coat he lunged out, slicing and stabbing!\",\n",
    "\"Story B Relevance\": \"Ana lost her coast\",\n",
    "\"Explaining the Differences for a Child\": \"In the first story, it says that Tom lunged out when he saw Ana's red coat. In the second story, it says that Ana lost her coat. The first sentence suggests that Ana still had her coat, while the second sentence suggests that Ana no longer had her coat.\",\n",
    "\"Verdict\": \"Contradiction\"\n",
    "},\n",
    "{\n",
    "\"StoryA\": \"London Calling is the third studio album by English punk rock band the Clash. It was released as a double album in the United Kingdom on 14 December 1979 by Columbia Records, and in the United States in January 1980 by Epic Records. \"London Calling\" is an album that incorporates a range of styles, including punk, reggae, rockabilly, ska, New Orleans R&B, pop, lounge jazz, and hard rock.\",\n",
    "\"StoryB\": \"Thanks to the rockabilly and R&B the album was released in the United States in 1980.\",\n",
    "\"Point of Contention\": \"Album being released in the United States in 1980\",\n",
    "\"Story A Relevance\": \"London Calling was released in the United States in January 1980 by Epic Records.\",\n",
    "\"Story B Relevance\": \"Thanks to the rockabilly and R&B the album was released in the United States in 1980.\",\n",
    "\"Explaining the Differences for a Child\": \"In the first story, it says that the album was released in the United States in January 1980. In the second story, it says that the album was released in the United States in 1980 thanks to the rockabilly and R&B the album. They both agree that it was released in 1980 but there is nothing in the first story that relates to whether it was released thanks to the rockabilly and R&B the album.\",\n",
    "\"Verdict\": \"Neutral\"\n",
    "}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4e1bef24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTargetExample(row):\n",
    "  return f\"\"\"{{\n",
    "    \"StoryA\": \"{row.context}\",\n",
    "    \"StoryB\": \"{row.hypothesis}\",\n",
    "    \"Point of Contention\":\"\"\"\n",
    "    \n",
    "def evaluateAnswer(res):\n",
    "    if \"entailment\" in res.lower()[-30:]:\n",
    "        return 'e'\n",
    "    elif \"contradiction\" in res.lower()[-30:]:\n",
    "        return 'c'\n",
    "    return 'n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ad12b087",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = pd.read_json(\"anli_v1.0/R3/dev.jsonl\",lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2d69e03e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>context</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>label</th>\n",
       "      <th>model_label</th>\n",
       "      <th>emturk</th>\n",
       "      <th>genre</th>\n",
       "      <th>reason</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50a5d4bc-bb8b-44f9-ba07-95dfaf5536ab</td>\n",
       "      <td>one of the orders issued by Ochola in April Lo...</td>\n",
       "      <td>The decision to move the photocopier business ...</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>False</td>\n",
       "      <td>news</td>\n",
       "      <td>I made an obvious inference from the text that...</td>\n",
       "      <td>r3_dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>08789750-b5fe-478d-8d3f-06a01e3a8b1e</td>\n",
       "      <td>If you can dream it, you can achieve it â€” unle...</td>\n",
       "      <td>The crowd believed they knew the name of the g...</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>False</td>\n",
       "      <td>news</td>\n",
       "      <td>Because the crowd was chanting its name, the c...</td>\n",
       "      <td>r3_dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a960c8cc-2f55-4269-a028-7f714479b068</td>\n",
       "      <td>The Kremlin described as \"complete nonsense\" o...</td>\n",
       "      <td>The Kremlin used the word nonsense multiple ti...</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>False</td>\n",
       "      <td>news</td>\n",
       "      <td>I based my statement on supposed word count ba...</td>\n",
       "      <td>r3_dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>95e97907-0267-45ae-89fc-7e1fce39ee77</td>\n",
       "      <td>Police said that a 21-year-old man was discove...</td>\n",
       "      <td>The victim was less than a quarter century old</td>\n",
       "      <td>e</td>\n",
       "      <td>c</td>\n",
       "      <td>False</td>\n",
       "      <td>news</td>\n",
       "      <td>21 is less than 25. I think the system got it ...</td>\n",
       "      <td>r3_dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5bd3435a-e52e-4688-9bc3-746b47c53469</td>\n",
       "      <td>Hurricane Harvey has caused devastating floods...</td>\n",
       "      <td>Houston is not the only area impacted by Hurri...</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>False</td>\n",
       "      <td>news</td>\n",
       "      <td>Louisiana was also impacted</td>\n",
       "      <td>r3_dev</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    uid  \\\n",
       "0  50a5d4bc-bb8b-44f9-ba07-95dfaf5536ab   \n",
       "1  08789750-b5fe-478d-8d3f-06a01e3a8b1e   \n",
       "2  a960c8cc-2f55-4269-a028-7f714479b068   \n",
       "3  95e97907-0267-45ae-89fc-7e1fce39ee77   \n",
       "4  5bd3435a-e52e-4688-9bc3-746b47c53469   \n",
       "\n",
       "                                             context  \\\n",
       "0  one of the orders issued by Ochola in April Lo...   \n",
       "1  If you can dream it, you can achieve it â€” unle...   \n",
       "2  The Kremlin described as \"complete nonsense\" o...   \n",
       "3  Police said that a 21-year-old man was discove...   \n",
       "4  Hurricane Harvey has caused devastating floods...   \n",
       "\n",
       "                                          hypothesis label model_label  \\\n",
       "0  The decision to move the photocopier business ...     e           n   \n",
       "1  The crowd believed they knew the name of the g...     e           n   \n",
       "2  The Kremlin used the word nonsense multiple ti...     e           n   \n",
       "3     The victim was less than a quarter century old     e           c   \n",
       "4  Houston is not the only area impacted by Hurri...     e           n   \n",
       "\n",
       "   emturk genre                                             reason     tag  \n",
       "0   False  news  I made an obvious inference from the text that...  r3_dev  \n",
       "1   False  news  Because the crowd was chanting its name, the c...  r3_dev  \n",
       "2   False  news  I based my statement on supposed word count ba...  r3_dev  \n",
       "3   False  news  21 is less than 25. I think the system got it ...  r3_dev  \n",
       "4   False  news                        Louisiana was also impacted  r3_dev  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c31fddc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = {}\n",
    "correct = 0\n",
    "done = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d0a1929b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 1 of 1200. Score: 1/1 (100.00%)\n",
      "Done 2 of 1200. Score: 2/2 (100.00%)\n",
      "Done 3 of 1200. Score: 3/3 (100.00%)\n",
      "Done 4 of 1200. Score: 4/4 (100.00%)\n",
      "Done 5 of 1200. Score: 5/5 (100.00%)\n",
      "Done 6 of 1200. Score: 6/6 (100.00%)\n",
      "Done 7 of 1200. Score: 7/7 (100.00%)\n",
      "Done 8 of 1200. Score: 8/8 (100.00%)\n",
      "Done 9 of 1200. Score: 8/9 (88.89%)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for row in dev.iterrows():\n",
    "    if row[0] in results_dict:\n",
    "        continue\n",
    "    newPrompt = basePrompt + createTargetExample(row[1])\n",
    "    res = query(newPrompt, stop=\"}\")\n",
    "    results_dict[row[0]] = {\n",
    "        \"res\": res,\n",
    "        \"label\": row[1].label,\n",
    "        \"pred\": evaluateAnswer(res)\n",
    "    }\n",
    "    done += 1\n",
    "    if evaluateAnswer(res) == row[1].label:\n",
    "        correct += 1\n",
    "    print(f\"Done {done} of {len(dev)}. Score: {correct}/{done} ({correct/done*100:.2f}%)\")\n",
    "    if done % 10 == 0:\n",
    "        with open(\"originalDavinci-inDepthFewShot.json\", \"w\") as f:\n",
    "            json.dump(results_dict, f)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1e20dece",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"originalDavinci-naivefewshot.json\", \"w\") as f:\n",
    "    json.dump(results_dict, f)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf2ed63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
